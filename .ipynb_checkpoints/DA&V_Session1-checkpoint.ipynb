{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc17833a-11e2-44b3-b7b0-f1858ef1f3b2",
   "metadata": {},
   "source": [
    "# Session 1: Foundations of Data Analysis, Python Fundamentals, and Data Ethics\n",
    "\n",
    "**Module:** Data Insights and Visualization  \n",
    "**Level:** 7 | **Credits:** 10  \n",
    "**Learning Outcomes Addressed:** LO1, LO4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6969e81-f353-4f50-a0b4-4fde2fc51774",
   "metadata": {},
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfee814-717c-42ea-86bb-af1a7ddbdade",
   "metadata": {},
   "source": [
    "## üìã Session Overview\n",
    "\n",
    "Welcome to the Data Insights and Visualization module! In this first session, we'll establish the foundational knowledge and skills needed for effective data analysis and visualization. By the end of this session, you'll understand the current data landscape, have a working Python environment, and appreciate the critical importance of data ethics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392dabfa-aac7-4499-b42e-46f21ba6e1c4",
   "metadata": {},
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de5caa5-50e7-4719-b75d-3a67d120ba5c",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef2aaa4-847f-4151-86dc-90a78582800e",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "#### By the end of this session, you will be able to:\n",
    "\n",
    "- **Explain the role of data analytics in modern business decision-making**\n",
    "- **Set up and navigate a Python data analysis environment**\n",
    "- **Identify different data types and quality dimensions**\n",
    "- **Apply fundamental data ethics principles**\n",
    "- **Perform basic data exploration using Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353672e0-a5ff-489c-b9a0-42929d8bdc60",
   "metadata": {},
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07abb758-3f57-4214-ab49-618fea41fe62",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f53ab2f-0b7a-475d-bf3f-c48ca2cc3093",
   "metadata": {},
   "source": [
    "## üåç Part 1: The Data Revolution in Business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63defc9c-a784-4c3f-b5b5-95bd4d1e4031",
   "metadata": {},
   "source": [
    "### 1.1 Course Introduction\n",
    "\n",
    "Welcome to **Data Insights and Visualization** - a journey that will transform how you approach data-driven decision making. In today's digital economy, organizations generate and collect vast amounts of data every second. The ability to extract meaningful insights from this data has become a critical competitive advantage.\n",
    "\n",
    "#### Module Learning Outcomes\n",
    "- **LO1:** Apply statistical and programming techniques to analyse complex structured and unstructured datasets\n",
    "- **LO2:** Design and implement data visualisations using contemporary tools and principles of perception\n",
    "- **LO3:** Critically interpret data patterns and trends for effective communication and decision-making\n",
    "- **LO4:** Evaluate data quality, integrity, and ethics in the data analysis lifecycle\n",
    "- **LO5:** Synthesise business intelligence from data to support strategy formulation and problem solving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43a259-086b-4850-98e0-3f38f7a043a6",
   "metadata": {},
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64c215-8b90-4574-b800-b857849878c2",
   "metadata": {},
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab2e364-244c-434a-a2e1-914140728066",
   "metadata": {},
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd57467-abf8-4937-8074-4ce25e903705",
   "metadata": {},
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecaf29b-2ce1-42a3-a8b8-f6f298f41bc6",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2798ec-2ff6-4eeb-a1d2-598d32005ac3",
   "metadata": {},
   "source": [
    "### 1.2 Current State of Data Analytics\n",
    "\n",
    "The global data sphere is expected to grow from 33 zettabytes in 2018 to 175 zettabytes by 2025. This explosion of data, often referred to as \"Big Data,\" is characterized by:\n",
    "\n",
    "- **Volume:** Massive amounts of data generated every second\n",
    "- **Velocity:** Real-time data processing requirements\n",
    "- **Variety:** Structured, semi-structured, and unstructured data formats\n",
    "- **Veracity:** Ensuring data quality and reliability\n",
    "- **Value:** Extracting actionable insights for business impact\n",
    "\n",
    "#### Real-World Applications\n",
    "- **Retail:** Customer behavior analysis, inventory optimization\n",
    "- **Healthcare:** Predictive diagnostics, treatment personalization\n",
    "- **Finance:** Risk assessment, fraud detection\n",
    "- **Manufacturing:** Predictive maintenance, quality control\n",
    "- **Marketing:** Campaign optimization, customer segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf4d39a-2acf-4042-9673-63eeb2fcc64a",
   "metadata": {},
   "source": [
    "### 1.3 Career Opportunities in Data Visualization\n",
    "\n",
    "The field offers diverse career paths:\n",
    "- **Data Analyst:** Focus on descriptive analytics and reporting\n",
    "- **Business Intelligence Analyst:** Strategic insights and dashboard creation\n",
    "- **Data Scientist:** Advanced analytics and machine learning\n",
    "- **Data Visualization Specialist:** Design and communication expert\n",
    "- **Chief Data Officer:** Strategic data leadership\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea8ee3-161d-4807-90a2-48371ef83d20",
   "metadata": {},
   "source": [
    "## üìä Part 2: Understanding Data Types and Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee06f7b-2716-40bb-9d98-04899015b243",
   "metadata": {},
   "source": [
    "### 2.1 Structured vs Unstructured Data\n",
    "\n",
    "#### Structured Data\n",
    "- **Definition:** Data organized in a predefined format (rows and columns)\n",
    "- **Examples:** Relational databases, CSV files, Excel spreadsheets\n",
    "- **Characteristics:** Easy to analyze, query, and visualize\n",
    "- **Storage:** Typically 20% of organizational data\n",
    "\n",
    "#### Semi-Structured Data\n",
    "- **Definition:** Data with some organizational properties but not fully structured\n",
    "- **Examples:** JSON, XML, NoSQL databases\n",
    "- **Characteristics:** Flexible schema, self-describing\n",
    "\n",
    "#### Unstructured Data\n",
    "- **Definition:** Data without predefined structure or organization\n",
    "- **Examples:** Text documents, images, videos, social media posts\n",
    "- **Characteristics:** Requires preprocessing, growing rapidly\n",
    "- **Storage:** Typically 80% of organizational data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea282a-ef97-441a-b226-45a203810a5c",
   "metadata": {},
   "source": [
    "### 2.2 Data Quality Dimensions\n",
    "\n",
    "High-quality data is essential for reliable analysis. The key dimensions include:\n",
    "\n",
    "1. **Accuracy:** Data correctly represents the real-world entity\n",
    "2. **Completeness:** All required data is present\n",
    "3. **Consistency:** Data is uniform across systems and time\n",
    "4. **Timeliness:** Data is up-to-date and available when needed\n",
    "5. **Validity:** Data conforms to defined formats and business rules\n",
    "6. **Uniqueness:** No unnecessary duplication of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44bbfe1-1053-4e40-a22c-799df44625d3",
   "metadata": {},
   "source": [
    "### 2.3 Common Data Formats\n",
    "\n",
    "- **CSV (Comma-Separated Values):** Simple, widely supported\n",
    "- **JSON (JavaScript Object Notation):** Web-friendly, hierarchical\n",
    "- **XML (eXtensible Markup Language):** Self-describing, verbose\n",
    "- **Parquet:** Columnar storage, optimized for analytics\n",
    "- **Database formats:** SQL Server, MySQL, PostgreSQL, MongoDB\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9670d8a6-ced5-4cbe-afba-dcf45e8290da",
   "metadata": {},
   "source": [
    "## üêç Part 3: Python Environment Setup and Basics\n",
    "\n",
    "### 3.1 Setting Up Your Development Environment\n",
    "\n",
    "#### Required Software\n",
    "1. **Python 3.8+** - Programming language\n",
    "2. **Jupyter Notebook** - Interactive development environment\n",
    "3. **Essential Libraries:**\n",
    "   - `pandas` - Data manipulation and analysis\n",
    "   - `numpy` - Numerical computing\n",
    "   - `matplotlib` - Basic plotting\n",
    "   - `seaborn` - Statistical visualization\n",
    "\n",
    "#### Installation Steps\n",
    "\n",
    "```bash\n",
    "# Using pip (Python package installer)\n",
    "pip install jupyter pandas numpy matplotlib seaborn\n",
    "\n",
    "# Using conda (Anaconda distribution)\n",
    "conda install jupyter pandas numpy matplotlib seaborn\n",
    "\n",
    "# Or install Anaconda distribution (recommended for beginners)\n",
    "# Download from: https://www.anaconda.com/products/distribution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17730182-df04-422a-a3cd-3932b7ed34f8",
   "metadata": {},
   "source": [
    "#### Starting Jupyter Notebook\n",
    "\n",
    "```bash\n",
    "# Navigate to your project directory\n",
    "cd /path/to/your/project\n",
    "\n",
    "# Start Jupyter Notebook\n",
    "jupyter notebook\n",
    "\n",
    "# Or Jupyter Lab (more advanced interface)\n",
    "jupyter lab\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f649e7-f747-418b-9ec0-62d49b309c06",
   "metadata": {},
   "source": [
    "### 3.2 Python Fundamentals for Data Analysis\n",
    "\n",
    "#### Essential Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "205f814d-48b8-41f7-b41c-b8f1607e8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists - Ordered collection of items\n",
    "sales_data = [100, 150, 200, 175, 300]\n",
    "product_names = ['Widget A', 'Widget B', 'Widget C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42bef23f-c749-43c4-accc-cb2d58f24c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries - Key-value pairs\n",
    "customer = {\n",
    "    'name': 'John Doe',\n",
    "    'age': 35,\n",
    "    'purchases': [100, 250, 75]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a6e0ddc-c117-4074-92f7-373006db2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy Arrays - Efficient numerical operations\n",
    "import numpy as np\n",
    "revenue = np.array([1000, 1200, 1100, 1400, 1300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c1efa6-54d5-46e6-b99a-bd6c698ac998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrames - Excel-like data structure\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'Product': ['A', 'B', 'C', 'D'],\n",
    "    'Sales': [100, 150, 200, 175],\n",
    "    'Region': ['North', 'South', 'East', 'West']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04f433-867c-4b8c-9dd4-5603decb3fd9",
   "metadata": {},
   "source": [
    "#### Basic Operations and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed2d22f-0969-4bf3-9567-70ddfb9b37a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics\n",
    "df['Sales'].mean()    # Average sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65241d5a-4474-40ef-a029-dfd3fc079d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sales'].median()  # Median sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa15893-1c9d-4baf-8ced-c517f42ff289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.69562819149833"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sales'].std()     # Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adb03862-947d-46ba-84e4-4f80549576d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>100</td>\n",
       "      <td>North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>150</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>200</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>175</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product  Sales Region\n",
       "0       A    100  North\n",
       "1       B    150  South\n",
       "2       C    200   East\n",
       "3       D    175   West"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data inspection\n",
    "df.head()        # First 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0622b7c-c678-4282-ab9a-963ffc3f58a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Product  4 non-null      object\n",
      " 1   Sales    4 non-null      int64 \n",
      " 2   Region   4 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 228.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()        # Data types and non-null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b431404-6aab-4247-bfd9-a661db2c4c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>156.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.695628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>137.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>162.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>181.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "count    4.000000\n",
       "mean   156.250000\n",
       "std     42.695628\n",
       "min    100.000000\n",
       "25%    137.500000\n",
       "50%    162.500000\n",
       "75%    181.250000\n",
       "max    200.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()    # Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a661a8a-5e85-43c1-bd3d-ac403a122187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape         # Number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94d9a822-b0a8-40cd-bbbb-46261dc4c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering and selection\n",
    "high_sales = df[df['Sales'] > 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5297427c-7784-4c26-a972-1ea012bd1791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>100</td>\n",
       "      <td>North</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product  Sales Region\n",
       "0       A    100  North"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "north_sales = df[df['Region'] == 'North']\n",
    "north_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a97bc08-56bd-4afc-a3d8-d5f1cccf1597",
   "metadata": {},
   "source": [
    "### 3.3 Reading and Writing Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4c085-1723-414f-84c4-330bed03ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading different file formats\n",
    "df_csv = pd.read_csv('sales_data.csv')\n",
    "df_excel = pd.read_excel('sales_data.xlsx', sheet_name='Q1')\n",
    "df_json = pd.read_json('customer_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36677259-0678-43d1-a5f0-0f487db81c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connections (example)\n",
    "# import sqlite3\n",
    "# conn = sqlite3.connect('company_database.db')\n",
    "# df_db = pd.read_sql_query('SELECT * FROM sales', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d339850-80a5-47ef-8f9e-d9247449de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing data files\n",
    "df.to_csv('processed_data.csv', index=False)\n",
    "df.to_excel('report.xlsx', sheet_name='Summary', index=False)\n",
    "df.to_json('output.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346eb0c-4a04-437e-91f5-0e9dba07a39b",
   "metadata": {},
   "source": [
    "## üõ°Ô∏è Part 4: Data Ethics and Governance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4b10d4-aea5-4c7a-9a1c-e2ffd91ad28a",
   "metadata": {},
   "source": [
    "### 4.1 Fundamental Ethical Principles\n",
    "\n",
    "Data ethics is not just about compliance‚Äîit's about building trust and ensuring responsible use of data. The core principles include:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6629dd5-3f34-4268-b84e-12f5af9be63f",
   "metadata": {},
   "source": [
    "#### Privacy\n",
    "- **Principle:** Individuals have the right to control their personal information\n",
    "- **Application:** Anonymization, pseudonymization, data minimization\n",
    "- **Example:** Removing personally identifiable information before analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d53006-da1d-441a-bfce-676344c09a45",
   "metadata": {},
   "source": [
    "#### Transparency\n",
    "- **Principle:** Be open about data collection, use, and decision-making processes\n",
    "- **Application:** Clear data collection notices, algorithm explainability\n",
    "- **Example:** Explaining how credit scores are calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bec7c4-bb32-433c-9589-bd8631de1d7d",
   "metadata": {},
   "source": [
    "#### Fairness and Non-discrimination\n",
    "- **Principle:** Avoid bias and ensure equitable treatment\n",
    "- **Application:** Regular bias audits, diverse training data\n",
    "- **Example:** Ensuring hiring algorithms don't discriminate by gender or ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a80a018-8213-47a3-878e-499ef69eb56f",
   "metadata": {},
   "source": [
    "#### Accountability\n",
    "- **Principle:** Take responsibility for data practices and their consequences\n",
    "- **Application:** Data governance frameworks, audit trails\n",
    "- **Example:** Maintaining records of data processing decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5a63f-29d1-47a4-813e-721440b46a2b",
   "metadata": {},
   "source": [
    "### 4.2 GDPR and Legal Compliance\n",
    "\n",
    "The General Data Protection Regulation (GDPR) sets the global standard for data protection:\n",
    "\n",
    "#### Key Requirements\n",
    "- **Lawful basis** for processing personal data\n",
    "- **Consent** must be freely given, specific, and informed\n",
    "- **Data subject rights** including access, rectification, and erasure\n",
    "- **Privacy by design** in system development\n",
    "- **Data Protection Impact Assessments** for high-risk processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1291345-aa99-4740-9ad3-7676ef2f5893",
   "metadata": {},
   "source": [
    "#### Practical Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b29774-6155-466a-a000-73a8aa3f4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Anonymizing personal data\n",
    "def anonymize_data(df):\n",
    "    # Remove direct identifiers\n",
    "    df = df.drop(['name', 'email', 'phone'], axis=1)\n",
    "    \n",
    "    # Generalize sensitive attributes\n",
    "    df['age_group'] = pd.cut(df['age'], bins=[0, 25, 45, 65, 100], \n",
    "                            labels=['18-25', '26-45', '46-65', '65+'])\n",
    "    df = df.drop(['age'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc571bd-3ffb-4c7a-b863-cf857427ffac",
   "metadata": {},
   "source": [
    "### 4.3 Bias and Fairness in Data Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec44d2d-b8fe-43bb-9c83-12c1613296a0",
   "metadata": {},
   "source": [
    "#### Types of Bias\n",
    "1. **Historical Bias:** Existing inequalities reflected in historical data\n",
    "2. **Representation Bias:** Certain groups underrepresented in data\n",
    "3. **Measurement Bias:** Systematic errors in data collection\n",
    "4. **Evaluation Bias:** Using inappropriate benchmarks\n",
    "5. **Aggregation Bias:** Assuming one model fits all groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b4ec8-260f-40ac-841d-0ae8e780e497",
   "metadata": {},
   "source": [
    "#### Detecting and Mitigating Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9fcea9e-35a3-4060-8175-7398cdfb6b8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gender'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gender'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Underrepresented groups: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munderrepresented\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m check_representation(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m, in \u001b[0;36mcheck_representation\u001b[1;34m(df, protected_attribute)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_representation\u001b[39m(df, protected_attribute):\n\u001b[1;32m----> 3\u001b[0m     distribution \u001b[38;5;241m=\u001b[39m df[protected_attribute]\u001b[38;5;241m.\u001b[39mvalue_counts(normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData distribution:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(distribution)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gender'"
     ]
    }
   ],
   "source": [
    "# Example: Checking for representation bias\n",
    "def check_representation(df, protected_attribute):\n",
    "    distribution = df[protected_attribute].value_counts(normalize=True)\n",
    "    print(\"Data distribution:\")\n",
    "    print(distribution)\n",
    "    \n",
    "    # Flag if any group represents less than 10% of data\n",
    "    underrepresented = distribution[distribution < 0.1]\n",
    "    if len(underrepresented) > 0:\n",
    "        print(f\"Warning: Underrepresented groups: {underrepresented.index.tolist()}\")\n",
    "\n",
    "# Usage\n",
    "check_representation(df, 'gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b3e48-dc45-4c2f-93b0-9c91b8bedcac",
   "metadata": {},
   "source": [
    "## üî¨ Part 5: Hands-on Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f7b85c-0f14-4761-914e-3fa1816941ea",
   "metadata": {},
   "source": [
    "### 5.1 Loading Your First Dataset\n",
    "\n",
    "Let's work with a sample sales dataset to practice our skills:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7675648a-32fe-447b-a7bb-855e24eb21be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (1000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_category</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>region</th>\n",
       "      <th>purchase_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Books</td>\n",
       "      <td>107.397463</td>\n",
       "      <td>40.287217</td>\n",
       "      <td>West</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Home</td>\n",
       "      <td>272.579841</td>\n",
       "      <td>38.726653</td>\n",
       "      <td>East</td>\n",
       "      <td>2023-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>37.753208</td>\n",
       "      <td>21.350141</td>\n",
       "      <td>South</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Books</td>\n",
       "      <td>119.290405</td>\n",
       "      <td>25.577674</td>\n",
       "      <td>East</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Books</td>\n",
       "      <td>23.861997</td>\n",
       "      <td>52.462785</td>\n",
       "      <td>West</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id product_category  purchase_amount  customer_age region  \\\n",
       "0            1            Books       107.397463     40.287217   West   \n",
       "1            2             Home       272.579841     38.726653   East   \n",
       "2            3      Electronics        37.753208     21.350141  South   \n",
       "3            4            Books       119.290405     25.577674   East   \n",
       "4            5            Books        23.861997     52.462785   West   \n",
       "\n",
       "  purchase_date  \n",
       "0    2023-01-01  \n",
       "1    2023-01-02  \n",
       "2    2023-01-03  \n",
       "3    2023-01-04  \n",
       "4    2023-01-05  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create sample data for demonstration\n",
    "np.random.seed(42)\n",
    "n_records = 1000\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'customer_id': range(1, n_records + 1),\n",
    "    'product_category': np.random.choice(['Electronics', 'Clothing', 'Books', 'Home'], n_records),\n",
    "    'purchase_amount': np.random.gamma(2, 50, n_records),\n",
    "    'customer_age': np.random.normal(40, 15, n_records),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_records),\n",
    "    'purchase_date': pd.date_range('2023-01-01', periods=n_records, freq='D')[:n_records]\n",
    "})\n",
    "\n",
    "# Add some missing values to make it realistic\n",
    "sample_data.loc[sample_data.sample(50).index, 'customer_age'] = np.nan\n",
    "sample_data.loc[sample_data.sample(30).index, 'purchase_amount'] = np.nan\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {sample_data.shape}\")\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50bcc7b-2536-4558-b163-2fe9a62ea47c",
   "metadata": {},
   "source": [
    "### 5.2 Basic Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50ff5a8d-200a-4aea-9839-a467cd7c986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET OVERVIEW ===\n",
      "Number of rows: 1000\n",
      "Number of columns: 6\n",
      "Data types:\n",
      "customer_id                  int64\n",
      "product_category            object\n",
      "purchase_amount            float64\n",
      "customer_age               float64\n",
      "region                      object\n",
      "purchase_date       datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "=== MISSING VALUES ===\n",
      "purchase_amount    30\n",
      "customer_age       50\n",
      "dtype: int64\n",
      "\n",
      "=== BASIC STATISTICS ===\n",
      "       customer_id  purchase_amount  customer_age        purchase_date\n",
      "count  1000.000000       970.000000    950.000000                 1000\n",
      "mean    500.500000       102.237702     39.606675  2024-05-14 12:00:00\n",
      "min       1.000000         2.295949    -12.071448  2023-01-01 00:00:00\n",
      "25%     250.750000        50.530915     29.523768  2023-09-07 18:00:00\n",
      "50%     500.500000        87.013091     39.613832  2024-05-14 12:00:00\n",
      "75%     750.250000       135.077412     50.306363  2025-01-19 06:00:00\n",
      "max    1000.000000       389.344521     85.929204  2025-09-26 00:00:00\n",
      "std     288.819436        69.046010     14.688192                  NaN\n"
     ]
    }
   ],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Number of rows: {len(sample_data)}\")\n",
    "print(f\"Number of columns: {len(sample_data.columns)}\")\n",
    "print(f\"Data types:\\n{sample_data.dtypes}\")\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing_values = sample_data.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "print(\"\\n=== BASIC STATISTICS ===\")\n",
    "print(sample_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e90be8-802e-4486-aed5-a6b739c66362",
   "metadata": {},
   "source": [
    "### 5.3 Identifying Data Quality Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcd16546-f770-4b30-b559-c250b20b6c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA QUALITY ASSESSMENT ===\n",
      "Duplicates: 0\n",
      "Outliers per column: {'customer_id': 0, 'purchase_amount': 31, 'customer_age': 3}\n",
      "Completeness per column:\n",
      "customer_id         100.0\n",
      "product_category    100.0\n",
      "purchase_amount      97.0\n",
      "customer_age         95.0\n",
      "region              100.0\n",
      "purchase_date       100.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def assess_data_quality(df):\n",
    "    \"\"\"Comprehensive data quality assessment\"\"\"\n",
    "    quality_report = {}\n",
    "    \n",
    "    # Completeness\n",
    "    completeness = (1 - df.isnull().sum() / len(df)) * 100\n",
    "    quality_report['completeness'] = completeness\n",
    "    \n",
    "    # Duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    quality_report['duplicates'] = duplicates\n",
    "    \n",
    "    # Outliers (for numerical columns)\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    outliers = {}\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
    "        outliers[col] = outlier_count\n",
    "    \n",
    "    quality_report['outliers'] = outliers\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# Assess our sample data\n",
    "quality_results = assess_data_quality(sample_data)\n",
    "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "print(f\"Duplicates: {quality_results['duplicates']}\")\n",
    "print(f\"Outliers per column: {quality_results['outliers']}\")\n",
    "print(f\"Completeness per column:\\n{quality_results['completeness']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e951a-0e7e-46ad-9b1b-6b9dcef2d793",
   "metadata": {},
   "source": [
    "## üìù Practical Exercises\n",
    "\n",
    "### Exercise 1: Environment Setup Verification\n",
    "\n",
    "1. Create a new Jupyter notebook\n",
    "2. Import all required libraries (pandas, numpy, matplotlib, seaborn)\n",
    "3. Create a simple DataFrame with sample data\n",
    "4. Display basic information about your DataFrame\n",
    "\n",
    "```python\n",
    "# Your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create your own sample dataset\n",
    "# Hint: Use at least 3 columns with different data types\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ec359-75aa-4154-854d-e759cc49653e",
   "metadata": {},
   "source": [
    "### Exercise 2: Data Quality Analysis\n",
    "\n",
    "Using the provided sample dataset:\n",
    "\n",
    "1. Calculate the percentage of missing values for each column\n",
    "2. Identify the data types of each column\n",
    "3. Find any duplicate rows\n",
    "4. Create a simple visualization showing the distribution of one numerical column\n",
    "\n",
    "```python\n",
    "# Your analysis code here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e07ff-a0be-445f-bc7c-6b8ffdc40d0f",
   "metadata": {},
   "source": [
    "### Exercise 3: Ethics Reflection\n",
    "\n",
    "Write a brief reflection (200-300 words) addressing the following questions:\n",
    "\n",
    "1. What ethical considerations should be taken into account when analyzing customer purchase data?\n",
    "2. How would you ensure privacy protection while still extracting valuable business insights?\n",
    "3. What potential biases might exist in retail sales data, and how could they impact analysis results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6385ea97-bc0f-4ff3-8a63-56c9128b191e",
   "metadata": {},
   "source": [
    "*Write your reflection in the markdown cell below:*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e74f81-d412-4a3b-8843-c117086ea435",
   "metadata": {},
   "source": [
    "## üéØ Session Deliverables\n",
    "\n",
    "### 1. Python Environment Setup\n",
    "- [ ] Python 3.8+ installed\n",
    "- [ ] Jupyter Notebook functional\n",
    "- [ ] All required libraries imported successfully\n",
    "- [ ] Sample notebook with basic operations completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cdab8b-5abc-4876-b4a8-dc96dd916e3b",
   "metadata": {},
   "source": [
    "### 2. Data Ethics Reflection\n",
    "Complete the ethics reflection exercise addressing:\n",
    "- Privacy considerations in data analysis\n",
    "- Potential sources of bias\n",
    "- Strategies for ethical data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5bd70a-bc9f-480f-b71b-7fc9a53b2da0",
   "metadata": {},
   "source": [
    "### 3. Basic Python Exercises\n",
    "Demonstrate competency in:\n",
    "- Creating and manipulating DataFrames\n",
    "- Basic data inspection techniques\n",
    "- Identifying data quality issues\n",
    "- Simple data visualization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb374191-45ef-4132-9ce6-778689e30b35",
   "metadata": {},
   "source": [
    "## üìö Additional Resources\n",
    "\n",
    "### Essential Reading\n",
    "- **Python for Data Analysis** by Wes McKinney (Chapter 1-3)\n",
    "- **The Data Science Ethics** by DJ Patil (Introduction)\n",
    "- **GDPR Guidelines** - ICO Data Protection Guide\n",
    "\n",
    "### Online Resources\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- [Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html)\n",
    "- [Ethics in AI and Data Science](https://www.partnershiponai.org/about/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912d7b5-22f1-41d7-bbfa-741b4481e16f",
   "metadata": {},
   "source": [
    "### Next Session Preview\n",
    "In Session 2, we'll dive deep into data preparation and cleaning techniques, learning how to handle missing values, outliers, and data transformation challenges.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68d2db-66b3-4aaf-80f2-47c962e35d2e",
   "metadata": {},
   "source": [
    "## ü§ù Getting Help\n",
    "\n",
    "- **Course Forum:** Post questions and share insights with peers\n",
    "- **Email:** To be Updated\n",
    "- **Documentation:** Always check official library documentation first\n",
    "\n",
    "Remember: The best way to learn data analysis is by doing. Experiment with the code, ask questions, and don't be afraid to make mistakes ‚Äì they're part of the learning process!\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c128f-e6aa-42b1-96f5-9644d4fec3fc",
   "metadata": {},
   "source": [
    "*\"Data is the new oil, but like oil, it needs to be refined to be valuable.\"* - Mathematical Processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
